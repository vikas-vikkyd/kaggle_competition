{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Model\nfrom tensorflow.python.keras.utils.vis_utils import plot_model\nfrom tensorflow.keras import backend as K\nfrom datetime import datetime\nimport random\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom tensorflow.keras.utils import Progbar\nimport time\nimport re\nfrom tensorflow.keras.applications import InceptionV3","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/shopee-product-matching/train.csv')\ndef plot_image(image_path, label_group, nrows, ncols):\n    images = train_data[train_data['label_group'] == label_group]['image'].values\n    plt.figure(figsize=(10,5))\n    f, axarr = plt.subplots(nrows, ncols)\n    f.set_figheight(15)\n    f.set_figwidth(15)\n    im = 0\n    for i in range(nrows):\n        for j in range(ncols):\n            title = train_data[train_data['image'] == images[im]]['title'].values[0]\n            img = plt.imread(os.path.join(image_path, images[im]))\n            im = im + 1\n            axarr[i, j].imshow(img)\n            axarr[i, j].set_xlabel(title)\ntrain_image_path = '/kaggle/input/shopee-product-matching/train_images/'\nplot_image(train_image_path, 4294197112, 2, 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"img_height = 224\nimg_width = 224\nbatch_size = 64\nexecution_mode = 'train-test'\nlearning_rate = 0.0001\nepochs = 5\nfile_path = '/kaggle/input/shopee-product-matching/train.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Prep","metadata":{}},{"cell_type":"code","source":"def create_pair():\n  pos_pair = []\n  neg_pair = []\n  train_data = pd.read_csv('../input/shopee-product-matching/train.csv')\n  all_label_group = set(train_data['label_group'])\n  for label in all_label_group:\n    #Positive pair\n    pos_list = train_data[train_data['label_group'] == label]['posting_id'].values\n    for i in range(len(pos_list)-1):\n      pos_pair.append([pos_list[i], pos_list[i+1], 1])\n    #Negative pair\n    neg_label = random.sample(all_label_group - set([label]), 1)[0]\n    neg_list = train_data[train_data['label_group'] == neg_label]['posting_id'].values\n    n = min(len(pos_list), len(neg_list))\n    for i in range(n):\n      neg_pair.append([pos_list[i], neg_list[i], 0])\n  #Merge pos and neg pair\n  all_pairs = pos_pair+ neg_pair\n  #Create DataaFrame\n  df_all_pairs = pd.DataFrame(data=all_pairs, columns=['posting_id1','posting_id2','label'])\n  df_all_pairs = pd.merge(df_all_pairs, train_data, left_on='posting_id1', right_on='posting_id', how='inner')\n  df_all_pairs = df_all_pairs[['posting_id1', 'posting_id2', 'image', 'title', 'label']]\n  df_all_pairs = df_all_pairs.rename(columns={'image':'image1', 'title':'title1'})\n  df_all_pairs = pd.merge(df_all_pairs, train_data, left_on='posting_id2', right_on='posting_id', how='inner')\n  df_all_pairs = df_all_pairs[['posting_id1', 'posting_id2','image1','title1','image', 'title', 'label']]\n  df_all_pairs = df_all_pairs.rename(columns={'image':'image2', 'title':'title2'})\n  return df_all_pairs\n\ndef get_true_matches(train_data):\n    all_matches = []\n    for index, row in train_data.iterrows():\n        posting_id1 = row['posting_id']\n        matching_postings = train_data[train_data['label_group'] == row['label_group']]['posting_id'].values\n        matching_postings = ' '.join(x for x in matching_postings)\n        all_matches.append([posting_id1,matching_postings])\n    return pd.DataFrame(data=all_matches, columns=['posting_id', 'matches'])\n\ndef get_f1_score(actual, predicted):\n    f_score = []\n    for index,row in actual.iterrows():\n        id = row['posting_id']\n        list = row['matches'].split()\n        pred_list = predicted[predicted['posting_id'] == id]['matches'].values[0].split()\n        ##F1 score\n        tags = set(list)\n        pred = set(pred_list)\n        tp = len(tags & pred)\n        fp = len(pred) - tp \n        fn = len(tags) - tp\n        if tp>0:\n            precision=float(tp)/(tp+fp)\n            recall=float(tp)/(tp+fn)\n            f_score.append(2*((precision*recall)/(precision+recall)))\n        else:\n            f_score.append(0)\n    return np.array(f_score).mean()\n@tf.function\ndef process_posting_id(image1, image2, label):\n    dct = {}\n    train_image_path = tf.constant('/kaggle/input/shopee-product-matching/train_images/')\n    #Process Image1\n    image1 = tf.strings.join([train_image_path, image1])\n    image1 = tf.io.read_file(image1)\n    image1 = tf.image.decode_jpeg(image1)\n    image1 = tf.image.convert_image_dtype(image1, tf.float32)\n    image1 = tf.image.resize(image1, [img_height, img_width])\n    #Process Image2\n    image2 = tf.strings.join([train_image_path, image2])\n    image2 = tf.io.read_file(image2)\n    image2 = tf.image.decode_jpeg(image2)\n    image2 = tf.image.convert_image_dtype(image2, tf.float32)\n    image2 = tf.image.resize(image2, [img_height, img_width])\n    #Get the lable\n    label = tf.expand_dims(tf.cast(label, tf.float32), axis=0)\n    dct['image1'] = image1\n    dct['image2'] = image2\n    dct['label'] = label\n    return dct","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Batched Dataset for training and validation","metadata":{}},{"cell_type":"code","source":"if execution_mode == 'train-test':\n    paired_train_data = create_pair()\n    training_data, testing_data = train_test_split(paired_train_data, test_size=0.1)\n    print(\"Total number of Training records: {}\".format(len(training_data['posting_id1'].values)))\n    print(\"Total number of validation records: {}\".format(len(testing_data['posting_id1'].values)))\n    #Training Data Gen\n    dataset = tf.data.Dataset.from_tensor_slices((training_data['image1'], training_data['image2'], training_data['label']))\n    dataset = dataset.map(process_posting_id, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    #Validation Data Gen\n    val_dataset = tf.data.Dataset.from_tensor_slices((testing_data['image1'], testing_data['image2'], testing_data['label']))\n    val_dataset = val_dataset.map(process_posting_id, num_parallel_calls=tf.data.AUTOTUNE)\n    val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\nelif execution_mode == 'train':\n    paired_train_data = create_pair()\n    training_data = paired_train_data\n    print(\"Total number of Training records: {}\".format(len(training_data['posting_id1'].values)))\n    #Training Data Gen\n    dataset = tf.data.Dataset.from_tensor_slices((training_data['image1'], training_data['image2'], training_data['label']))\n    dataset = dataset.map(process_posting_id, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def base_model():\n    #For Image Data\n    input = tf.keras.layers.Input(shape=(img_height,img_width,3), name='base_image_input')\n    x = tf.keras.layers.Conv2D(32, (3,3), activation='relu')(input)\n    x = tf.keras.layers.MaxPooling2D((2,2))(x)\n    x = tf.keras.layers.Conv2D(64, (3,3), activation='relu')(x)\n    x = tf.keras.layers.MaxPooling2D((2,2))(x)\n    x = tf.keras.layers.Conv2D(128, (3,3), activation='relu')(x)\n    x = tf.keras.layers.MaxPooling2D((2,2))(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(256, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    x = tf.keras.layers.Dense(512, activation='relu')(x)\n    #define model\n    model = Model(inputs=input, outputs=x)\n    return model\ndef euclidean_distance(vects):\n    x, y = vects\n    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\ndef eucl_dist_output_shape(shapes):\n    shape1, shape2 = shapes\n    return (shape1[0], 1)\ndef contrastive_loss_with_margin(margin):\n    def contrastive_loss(y_true, y_pred):\n        square_pred = K.square(y_pred)\n        margin_square = K.square(K.maximum(margin - y_pred, 0))\n        return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n    return contrastive_loss\n#Define Model\nbase_network = base_model()\n\ninput_a = tf.keras.layers.Input(shape=(img_height, img_width, 3), name='input_a')\nvec_output_a = base_network(input_a)\n\ninput_b = tf.keras.layers.Input(shape=(img_height, img_width, 3), name='input_b')\nvec_output_b = base_network(input_b)\noutput = tf.keras.layers.Lambda(euclidean_distance, name='output_layer', \n                                    output_shape=eucl_dist_output_shape)([vec_output_a, vec_output_b])\nmy_model = Model(inputs=[input_a, input_b], outputs=output)\n#plot_model(base_network, show_shapes=True, show_layer_names=True, to_file='base-model.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizer and Loss","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\nloss = contrastive_loss_with_margin(1)\nmy_model.compile(optimizer=optimizer, loss=loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Training","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef train_model(my_model, dataset, optimizer, loss):\n    with tf.GradientTape() as tap:\n        input_a = dataset['image1']\n        input_b = dataset['image2']\n        label = dataset['label']\n        output = my_model([input_a, input_b])\n        loss_value = loss(label, output)\n    gradients = tap.gradient(loss_value, my_model.trainable_weights)\n    optimizer.apply_gradients(zip(gradients, my_model.trainable_weights))\n    return loss_value\n\ndef train_data_for_one_epoch(dataset, my_model, optimizer, loss):\n    losses = []\n    for step, single_batch in enumerate(dataset):\n        time.sleep(0.3)\n        loss_value = train_model(my_model, single_batch, optimizer, loss)\n        losses.append(loss_value.numpy())\n        pb_i.add(batch_size)\n    return np.mean(losses)\n\ndef perform_validation(my_model, val_dataset):\n    val_loss = []\n    for step, single_batch in enumerate(val_dataset):\n        input_a = single_batch['image1']\n        input_b = single_batch['image2']\n        y_pred = my_model([input_a, input_b])\n        val_loss.append(loss(single_batch['label'], y_pred))\n    return np.mean(val_loss)\n\n#Custom Training\nif execution_mode == 'train-test' or execution_mode == 'train':\n    epoch = range(epochs)\n    num_training_samples = training_data['image1'].count()\n    for epc in epoch:\n        pb_i = Progbar(num_training_samples)\n        epc = epc + 1\n        start_time = datetime.now()\n        #Train model for one epoch\n        losses = train_data_for_one_epoch(dataset, my_model, optimizer, loss)\n        val_loss = perform_validation(my_model, val_dataset)\n        #val_loss = 0\n        #Train End time for one epoch\n        end_time = datetime.now()\n        time_taken_for_one_epoch = (end_time-start_time).total_seconds()\n        print('\\n Epoch %s/%s time taken: %.4f: Train loss: %.4f  Validation Loss: %.4f,' % \\\n          (epc,epochs, float(time_taken_for_one_epoch), float(losses), float(val_loss)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"if execution_mode == 'train-test' or execution_mode == 'train':\n    base_network.save('base_network_cnn.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"#Read model for inference\nif execution_mode == 'train-test' or execution_mode == 'train':\n    base_network = tf.keras.models.load_model('base_network_cnn.h5')\n    #None\nelse:\n    base_network = tf.keras.models.load_model('../input/shopee-base-network-cnn-final/base_network_cnn.h5')\n#base_network = tf.keras.models.load_model('../input/shopee-base-nework-cnn/base_network_cnn.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_images(image):\n    dct = {}\n    image_path = '/kaggle/input/shopee-product-matching/train_images/'\n    image_path = tf.constant(image_path)\n    #Process Image\n    img = tf.strings.join([image_path, image])\n    img = tf.io.read_file(img)\n    img = tf.image.decode_jpeg(img)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, [img_height, img_width])\n    dct['image'] = img\n    #dct['title'] = title\n    return dct\n@tf.function\ndef process_test_images(image):\n    dct = {}\n    image_path = tf.constant('/kaggle/input/shopee-product-matching/test_images/')\n    #Process Image\n    img = tf.strings.join([image_path, image])\n    img = tf.io.read_file(img)\n    img = tf.image.decode_jpeg(img)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, [img_height, img_width])\n    dct['image'] = img\n    #dct['title'] = title\n    return dct\ndef make_prediction(data, train_test, thld):\n    pred_dataset = tf.data.Dataset.from_tensor_slices((data['image']))\n    if train_test == 'train':\n        pred_dataset = pred_dataset.map(process_images, num_parallel_calls=tf.data.AUTOTUNE)\n    else:\n        pred_dataset = pred_dataset.map(process_test_images, num_parallel_calls=tf.data.AUTOTUNE)\n    \n    pred_dataset = pred_dataset.batch(batch_size).prefetch(1)\n    pred_vecs = []\n    for step, single_batch in enumerate(pred_dataset):\n        if step == 0:\n            pred_vecs = base_network.predict(single_batch['image'])\n        else:\n            pred_vec = base_network.predict(single_batch['image'])\n            pred_vecs = np.concatenate((pred_vecs,pred_vec), axis=0)\n    all_posting_ids = data['posting_id'].values\n    iter1 = 0\n    all_matches = []\n    for vec1 in pred_vecs:\n        vec1 = np.expand_dims(vec1, axis=0)\n        dist = np.sqrt((np.square(vec1[:,np.newaxis]-pred_vecs).sum(axis=2)))\n        match_indices = np.where(dist[0] < thld)[0]\n        res_list = [all_posting_ids[i] for i in match_indices]\n        matches = ' '.join(x for x in res_list)\n        all_matches.append([all_posting_ids[iter1], matches])\n        iter1 = iter1 + 1\n    return pd.DataFrame(data=all_matches, columns=['posting_id', 'matches'])\n\n#Evaluation on Training Data\ntrain_data = pd.read_csv('../input/shopee-product-matching/train.csv')\nif execution_mode == 'train-test':\n    #Evaluation on Test Data\n    id1 = testing_data['posting_id1'].unique()\n    id2 = testing_data['posting_id2'].unique()\n    ids = set(np.concatenate((id1, id2), axis=None))\n    val_df = pd.DataFrame(data=ids, columns=['lkp_posting_id'])\n    val_df = pd.merge(train_data, val_df, left_on=['posting_id'], right_on=['lkp_posting_id'], \n                      how='inner')['label_group'].unique()\n    val_df = pd.DataFrame(data=val_df, columns=['lkp_label_group'])\n    val_df = pd.merge(train_data, val_df, left_on=['label_group'], right_on=['lkp_label_group'], how='inner')\n    true_matches = get_true_matches(val_df)\n    predicted_matches = make_prediction(val_df, 'train', 0.14)\n    print(\"Validation F1 Score: {}\".format(get_f1_score(true_matches, predicted_matches)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#.08--0.5217170441029266\n#.09--0.5265689416677081\n#-.1-0.5284976862896783\n#.11-0.5293373935699899\n#.12-0.525426784414794\n#.15-0.47364145037329164\n#Complex model\n#.11--0.5295349473869791\n#.08--0.5320256574354766\n#.06--0.5194226717796155\n#.05--0.510886131209785\n#learning rate-.0001\n#.1--0.5343608935770062\n#.08--0.5230246529858268\n#.12--0.5440129518164996\n#.14--0.548717885521488\n#.16--0.546046573605273\n#########\n#.1 = 0.5189557717506046\n#.08--0.5079437031808338","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some manual Evaluation","metadata":{}},{"cell_type":"code","source":"if execution_mode == 'train-test':\n    for dat in val_dataset:\n        idx = 8\n        img1 = dat['image1'].numpy()[idx]\n        img2 = dat['image2'].numpy()[idx]\n        label = dat['label'].numpy()[idx]\n        plt.figure()\n        plt.imshow(img1)\n        plt.figure()\n        plt.imshow(img2)\n        plt.show()\n        print(label)\n        #print(my_model.predict([np.expand_dims(img1, axis=0), np.expand_dims(img2, axis=0)]))\n        vec1 = base_network.predict(np.expand_dims(img1, axis=0))\n        vec2 = base_network.predict(np.expand_dims(img2, axis=0))\n        #print(euclidean_distance([vec1, vec2]))\n        print(np.sqrt((np.square(vec1[:,np.newaxis]-vec2).sum(axis=2))))\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')\nsubmission_df = make_prediction(test_data, 'test', 0.1)\nsubmission_df.to_csv('./submission.csv', index=False)\n#submission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}