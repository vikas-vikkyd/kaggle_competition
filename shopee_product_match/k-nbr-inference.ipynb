{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nfrom sklearn.neighbors import NearestNeighbors","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameter","metadata":{}},{"cell_type":"code","source":"img_height = 75\nimg_width = 75\nbatch_size = 64\noov_token = '<oov>'\nnum_words = 20000\ntruncating = 'post'\npadding = 'post'\nembedding_dim = 50\nmax_len = 20\n#execution_mode = 'get_threshold'\nexecution_mode = 'submission'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_network_cnn = tf.keras.models.load_model('../input/shopee-base-network-cnn-final/base_network_cnn.h5')\nbase_network_seq = tf.keras.models.load_model('../input/shopee-product-matching-seq-final/base_network_seq.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data prep","metadata":{}},{"cell_type":"code","source":"def create_sequence(data, col):\n    seq = np.array(pad_sequences(tokenizer.texts_to_sequences([x for x in data[col].values]), maxlen=max_len, \n              truncating=truncating, padding=padding))\n    return seq\ndef clean_data(x):\n    x = x.replace('!', '')\n    x = x.replace('\"', '')\n    x = x.replace('#', '')\n    x = x.replace('$', '')\n    x = x.replace('%', '')\n    x = x.replace('&', '')\n    x = x.replace(\"'\", '')\n    x = x.replace('(', '')\n    x = x.replace(')', '')\n    x = x.replace('*', '')\n    x = x.replace('+', '')\n    x = x.replace(',', '')\n    x = x.replace('-', '')\n    x = x.replace('.', '')\n    x = x.replace('/', '')\n    x = x.replace('0', '')\n    x = x.replace('1', '')\n    x = x.replace('2', '')\n    x = x.replace('3', '')\n    x = x.replace('4', '')\n    x = x.replace('5', '')\n    x = x.replace('6', '')\n    x = x.replace('7', '')\n    x = x.replace('8', '')\n    x = x.replace('9', '')\n    x = x.replace(':', '')\n    x = x.replace(';', '')\n    x = x.replace('<', '')\n    x = x.replace('=', '')\n    x = x.replace('>', '')\n    x = x.replace('?', '')\n    x = x.replace('@', '')\n    x = x.replace('[', '')\n    x = x.replace('\\\\', '')\n    x = x.replace(']', '')\n    x = x.replace('^', '')\n    x = x.replace('_', '')\n    x = x.replace('`', '')\n    x = x.replace('{', '')\n    x = x.replace('|', '')\n    x = x.replace('}', '')\n    x = x.replace('~', '')\n    return x\n\n#Learn Tokenizer for sequence\ntrain_data = pd.read_csv('../input/shopee-product-matching/train.csv')\ntrain_data['title'] = train_data['title'].apply(clean_data)\ntitles = []\nfor index, row in train_data.iterrows():\n    titles.append(row['title'])\ntokenizer = Tokenizer(oov_token=oov_token, num_words=num_words)\ntokenizer.fit_on_texts(titles)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get Embeddings","metadata":{}},{"cell_type":"code","source":"def process_test_images(image):\n    dct = {}\n    image_path = tf.constant('/kaggle/input/shopee-product-matching/test_images/')\n    #Process Image\n    img = tf.strings.join([image_path, image])\n    img = tf.io.read_file(img)\n    img = tf.image.decode_jpeg(img)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, [img_height, img_width])\n    dct['image'] = img\n    return dct\ndef process_train_images(image):\n    dct = {}\n    image_path = tf.constant('/kaggle/input/shopee-product-matching/train_images/')\n    #Process Image\n    img = tf.strings.join([image_path, image])\n    img = tf.io.read_file(img)\n    img = tf.image.decode_jpeg(img)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, [img_height, img_width])\n    dct['image'] = img\n    return dct\ndef get_image_embeddings(data):\n    pred_dataset = tf.data.Dataset.from_tensor_slices((data['image']))\n    if execution_mode == 'submission':\n        pred_dataset = pred_dataset.map(process_test_images, num_parallel_calls=tf.data.AUTOTUNE)\n    else:\n        pred_dataset = pred_dataset.map(process_train_images, num_parallel_calls=tf.data.AUTOTUNE)\n    pred_dataset = pred_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    pred_vecs = []\n    for step, single_batch in enumerate(pred_dataset):\n        if step == 0:\n            pred_vecs = base_network_cnn.predict(single_batch['image'])\n        else:\n            pred_vec = base_network_cnn.predict(single_batch['image'])\n            pred_vecs = np.concatenate((pred_vecs,pred_vec), axis=0)\n    return pred_vecs\n\ndef get_title_embeddings(data):\n    weight_metrix = base_network_seq.layers[1].get_weights()[0]\n    sequences = create_sequence(data, 'title')\n    pred_vecs = []\n    for seq in sequences:\n        i = 0\n        emb = np.zeros((embedding_dim))\n        for idx in seq:\n            if idx != 0:\n                emb = emb + np.array(weight_metrix[idx])\n                i = i + 1\n        emb = emb/i\n        pred_vecs.append(emb)\n    return np.array(pred_vecs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Find threshold","metadata":{}},{"cell_type":"code","source":"def get_true_matches(train_data):\n    all_matches = []\n    for index, row in train_data.iterrows():\n        posting_id1 = row['posting_id']\n        matching_postings = train_data[train_data['label_group'] == row['label_group']]['posting_id'].values\n        matching_postings = ' '.join(x for x in matching_postings)\n        all_matches.append([matching_postings])\n    return all_matches\ndef get_f1_score(actual, predicted):\n    act_list = actual[0].split()\n    pred_list = predicted.split()\n    ##F1 score\n    tags = set(act_list)\n    pred = set(pred_list)\n    tp = len(tags & pred)\n    fp = len(pred) - tp \n    fn = len(tags) - tp\n    if tp>0:\n        precision=float(tp)/(tp+fp)\n        recall=float(tp)/(tp+fn)\n        f_score = 2*((precision*recall)/(precision+recall))\n    else:\n        f_score=0\n    return f_score\n\nif execution_mode == 'get_threshold':\n    #will use 10% of training data\n    train_data = pd.read_csv('../input/shopee-product-matching/train.csv')\n    train_data['title'] = train_data['title'].apply(clean_data)\n    image_embeddings = get_image_embeddings(train_data)\n    title_embeddings = get_title_embeddings(train_data)\n    #Get all True Matches\n    y_true_all = get_true_matches(train_data)\n    all_posting_id = train_data['posting_id'].values\n    nbrs_image = NearestNeighbors(n_neighbors=50, algorithm='auto').fit(image_embeddings)\n    nbrs_title = NearestNeighbors(n_neighbors=50, algorithm='auto').fit(title_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_thresold(nbrs_image, nbrs_title, image_embeddings, title_embeddings, thrld_img, thrld_seq):\n    f1_score = []\n    for i in range(image_embeddings.shape[0]):\n        #Using Image Embeddings\n        distances, indices = nbrs_image.kneighbors(np.expand_dims(image_embeddings[i], axis=0))\n        idx = np.where(distances[0] < thrld_img)[0]\n        idx = indices[0,idx]\n        y_pred_img = all_posting_id[idx]\n        #Using Image Embeddings\n        distances, indices = nbrs_title.kneighbors(np.expand_dims(title_embeddings[i], axis=0))\n        idx = np.where(distances[0] < thrld_seq)[0]\n        idx = indices[0,idx]\n        y_pred_title = all_posting_id[idx]\n        #Merge both prediction\n        y_pred = set(np.concatenate((y_pred_img, y_pred_title), axis=0))\n        y_pred = ' '.join(x for x in y_pred)\n        f1_score.append(get_f1_score(y_true_all[i], y_pred))\n        if i > 4000:\n            break\n    return np.mean(f1_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#score = get_thresold(nbrs_image, nbrs_title, image_embeddings, title_embeddings, 0.1, 0.05)\n#print(score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"def make_prediction(nbrs_image, nbrs_title, image_embeddings, title_embeddings, thrld_img, thrld_seq):\n    all_matches = []\n    for i in range(image_embeddings.shape[0]):\n        #Using Image Embeddings\n        distances, indices = nbrs_image.kneighbors(np.expand_dims(image_embeddings[i], axis=0))\n        idx = np.where(distances[0] < thrld_img)[0]\n        idx = indices[0,idx]\n        y_pred_img = all_posting_id[idx]\n        #Using Image Embeddings\n        distances, indices = nbrs_title.kneighbors(np.expand_dims(title_embeddings[i], axis=0))\n        idx = np.where(distances[0] < thrld_seq)[0]\n        idx = indices[0,idx]\n        y_pred_title = all_posting_id[idx]\n        #Merge both prediction\n        y_pred = set(np.concatenate((y_pred_img, y_pred_title), axis=0))\n        y_pred = ' '.join(x for x in y_pred)\n        all_matches.append([all_posting_id[i], y_pred])\n    return pd.DataFrame(data=all_matches, columns=['posting_id', 'matches'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if execution_mode == 'submission':\n    test_data = pd.read_csv('../input/shopee-product-matching/test.csv')\n    test_data['title'] = test_data['title'].apply(clean_data)\n    image_embeddings = get_image_embeddings(test_data)\n    title_embeddings = get_title_embeddings(test_data)\n    all_posting_id = test_data['posting_id'].values\n    if image_embeddings.shape[0] < 50:\n        k = image_embeddings.shape[0]\n    else:\n        k = 50\n    nbrs_image = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(image_embeddings)\n    nbrs_title = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(title_embeddings)\n    submission_df = make_prediction(nbrs_image, nbrs_title, image_embeddings, title_embeddings, 0.1, 0.05)\n    submission_df.to_csv('./submission.csv', index=False)\n    #submission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}