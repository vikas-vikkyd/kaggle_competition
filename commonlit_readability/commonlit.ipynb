{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nimport xgboost\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.svm import SVR","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-31T06:34:26.263558Z","iopub.execute_input":"2021-07-31T06:34:26.26388Z","iopub.status.idle":"2021-07-31T06:34:26.268898Z","shell.execute_reply.started":"2021-07-31T06:34:26.263852Z","shell.execute_reply":"2021-07-31T06:34:26.268224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntrain_data['len'] = train_data['excerpt'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:34:27.526412Z","iopub.execute_input":"2021-07-31T06:34:27.526784Z","iopub.status.idle":"2021-07-31T06:34:27.602175Z","shell.execute_reply.started":"2021-07-31T06:34:27.526755Z","shell.execute_reply":"2021-07-31T06:34:27.600896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"num_words = 15000\noov_token = '<oov>'\n#Define Max_len\nmax_len = 0\nfor excerpt in train_data['excerpt'].values:\n    excerpt_len = len(excerpt.split())\n    if excerpt_len > max_len:\n        max_len = excerpt_len\n#max_len = 150\npadding = 'pre'\ntruncating = 'pre'\nembedding_dim = 100","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:34:29.506978Z","iopub.execute_input":"2021-07-31T06:34:29.507317Z","iopub.status.idle":"2021-07-31T06:34:29.543869Z","shell.execute_reply.started":"2021-07-31T06:34:29.507285Z","shell.execute_reply":"2021-07-31T06:34:29.542687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def prep_text(text_df):\n    text_df = text_df.str.replace(\"\\n\",\"\",regex=False)\n    text_df = text_df.replace(',', ' ').replace('.', ' ')\n    return text_df.str.replace(\"\\'s\",r\"s\",regex=True).values\ntrain_data[\"excerpt\"] = prep_text(train_data[\"excerpt\"])\ntokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\ntokenizer.fit_on_texts(train_data['excerpt'].values)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:34:32.786496Z","iopub.execute_input":"2021-07-31T06:34:32.786852Z","iopub.status.idle":"2021-07-31T06:34:33.246263Z","shell.execute_reply.started":"2021-07-31T06:34:32.786821Z","shell.execute_reply":"2021-07-31T06:34:33.245355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre Trained Embeddings","metadata":{}},{"cell_type":"code","source":"#read embedding file\nembedding_dic = {}\nglove_file = '../input/glove6b100dtxt/glove.6B.100d.txt'\nwith open(glove_file, 'r') as text_file:\n    for line in text_file:\n        embedding_dic[line.split()[0]] = np.asarray(line.split()[1:], dtype=np.float32)\ntext_file.close()\nword_embeddings = np.zeros((num_words, embedding_dim))\nfor word, index in tokenizer.word_index.items():\n    emb_vector = embedding_dic.get(word)\n    if emb_vector is not None:\n        word_embeddings[index] = emb_vector\n    if index == num_words - 1:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:34:35.598422Z","iopub.execute_input":"2021-07-31T06:34:35.598761Z","iopub.status.idle":"2021-07-31T06:34:48.370659Z","shell.execute_reply.started":"2021-07-31T06:34:35.598734Z","shell.execute_reply":"2021-07-31T06:34:48.369692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Prep","metadata":{}},{"cell_type":"code","source":"training_data, testing_data = train_test_split(train_data, test_size=0.2, random_state=1234)\n#training_data = train_data\ntrain_sentences = training_data['excerpt'].values\ntrain_label = training_data['target'].values\ntest_sentences = testing_data['excerpt'].values\ntest_label = testing_data['target'].values\n#Tokenize\ntrain_sequences = tokenizer.texts_to_sequences(train_sentences)\ntest_sequences = tokenizer.texts_to_sequences(test_sentences)\n#Pad sequences\ntrain_padded = pad_sequences(train_sequences, maxlen=max_len, padding=padding, truncating=truncating)\ntest_padded = pad_sequences(test_sequences, maxlen=max_len, padding=padding, truncating=truncating)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:34:50.890771Z","iopub.execute_input":"2021-07-31T06:34:50.891195Z","iopub.status.idle":"2021-07-31T06:34:51.268876Z","shell.execute_reply.started":"2021-07-31T06:34:50.891158Z","shell.execute_reply":"2021-07-31T06:34:51.267816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"\ndef all_model(model_type):\n    if model_type == 'emb':\n        inputs = tf.keras.layers.Input(shape=(max_len))\n        x = tf.keras.layers.Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[word_embeddings], \\\n                                      trainable=True, input_length=max_len)(inputs)\n        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n        x = tf.keras.layers.Dense(256, activation='relu')(x)\n        x = tf.keras.layers.Dropout(0.2)(x)\n        x = tf.keras.layers.Dense(512, activation='relu')(x)\n        x = tf.keras.layers.Dropout(0.2)(x)\n        x = tf.keras.layers.Dense(1024, activation='relu')(x)\n        x = tf.keras.layers.Dropout(0.1)(x)\n        out = tf.keras.layers.Dense(1)(x)\n        #out = tf.keras.layers.Lambda(lambda a : a + (a/abs(a))*0.03)(x)\n    if model_type == 'rnn':\n        inputs = tf.keras.layers.Input(shape=(max_len))\n        x = tf.keras.layers.Embedding(input_dim=num_words, output_dim=embedding_dim,weights=[word_embeddings], \\\n                                      trainable=True, input_length=max_len)(inputs)\n        x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout=0.2, return_sequences=False))(x)\n        x = tf.keras.layers.Dense(128, activation='relu')(x)\n        x = tf.keras.layers.Dropout(0.2)(x)\n        x = tf.keras.layers.Dense(256, activation='relu')(x)\n        x = tf.keras.layers.Dropout(0.2)(x)\n        #x = tf.keras.layers.Dense(1024, activation='relu')(x)\n        #x = tf.keras.layers.Dropout(0.2)(x)\n        out = tf.keras.layers.Dense(1)(x)\n    model = tf.keras.models.Model(inputs=inputs, outputs=out)\n    return model\nmodel = all_model('emb')\noptimizer = tf.keras.optimizers.Adam()\nmodel.compile(optimizer=optimizer, loss='mse', metrics=tf.keras.metrics.RootMeanSquaredError())\n#model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:34:53.354873Z","iopub.execute_input":"2021-07-31T06:34:53.355209Z","iopub.status.idle":"2021-07-31T06:34:53.441121Z","shell.execute_reply.started":"2021-07-31T06:34:53.355179Z","shell.execute_reply":"2021-07-31T06:34:53.440121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_padded, train_label, validation_data=(test_padded, test_label), batch_size=64, epochs=5)\n#history = model.fit(train_padded, train_label, batch_size=64, epochs=5)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:35:01.475132Z","iopub.execute_input":"2021-07-31T06:35:01.475516Z","iopub.status.idle":"2021-07-31T06:35:06.146213Z","shell.execute_reply.started":"2021-07-31T06:35:01.475475Z","shell.execute_reply":"2021-07-31T06:35:06.145263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.plot(history.history['root_mean_squared_error'])\nplt.plot(history.history['val_root_mean_squared_error'])","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:35:08.438383Z","iopub.execute_input":"2021-07-31T06:35:08.438746Z","iopub.status.idle":"2021-07-31T06:35:08.591089Z","shell.execute_reply.started":"2021-07-31T06:35:08.438712Z","shell.execute_reply":"2021-07-31T06:35:08.589984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extractor Model","metadata":{}},{"cell_type":"code","source":"#Define Feature Extractor\nfor layer in model.layers:\n    layer.trainable = False\nout_put = model.layers[5].output\nfeature_extractor = tf.keras.models.Model(inputs=[model.inputs], outputs=[out_put])\n#Create Feature\nfeatures = feature_extractor.predict(train_padded)\ndf_features = pd.DataFrame(data=features)\ndf_features['target'] = train_label\n#df_features.to_csv('features_from_emb.csv', index=False)\n\n#Create validation data\nval_features = feature_extractor.predict(test_padded)\ndf_features_val = pd.DataFrame(data=val_features)\ndf_features_val['target'] = test_label\n\n#Feature Selection\n#Remove highly correlated features\ndef get_correlated_features(data, thld):\n    data = data.drop(columns=['target'], axis=1)\n    df = data.corr()\n    all_columns = df.columns\n    highly_correlated = [] \n    for index, row in df.iterrows():\n        for col in all_columns:\n            if index != col and abs(row[col]) > thld:\n                highly_correlated.append(col)\n    return list(set(highly_correlated))\n\nhighly_correlated_features = get_correlated_features(df_features, 0.8)\ndf_features = df_features.drop(columns=highly_correlated_features, axis=1)\n\n#Slection using feature importance\nreg = RandomForestRegressor()\nX = df_features.drop(columns=['target'], axis=1)\ny = df_features['target']\nreg.fit(X, y)\narr = reg.feature_importances_\nFEATURE_COLUMNS = list(np.array(X.columns[arr > 0]))\nFEATURE_COLUMNS.append('target')","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:35:11.478124Z","iopub.execute_input":"2021-07-31T06:35:11.478487Z","iopub.status.idle":"2021-07-31T06:35:24.411027Z","shell.execute_reply.started":"2021-07-31T06:35:11.478454Z","shell.execute_reply":"2021-07-31T06:35:24.41023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training\ntrain = df_features[FEATURE_COLUMNS]\ntrain_x = train.drop(columns=['target'], axis=1)\ntrain_y = train['target']\n#Validation\nval_data = df_features_val[FEATURE_COLUMNS]\nval_x = val_data.drop(columns=['target'], axis=1)\nval_y = val_data['target']","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:35:26.885941Z","iopub.execute_input":"2021-07-31T06:35:26.886627Z","iopub.status.idle":"2021-07-31T06:35:26.90111Z","shell.execute_reply.started":"2021-07-31T06:35:26.886557Z","shell.execute_reply":"2021-07-31T06:35:26.899951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model**","metadata":{}},{"cell_type":"code","source":"#Ridge\nridge_model = Ridge(alpha=3.5, random_state=1234)\nridge_model.fit(train_x, train_y)\nprint(\"Training:\", mean_squared_error(train_y, ridge_model.predict(train_x), squared=False))\nprint(\"Validation:\", mean_squared_error(val_y, ridge_model.predict(val_x), squared=False))","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:35:29.189828Z","iopub.execute_input":"2021-07-31T06:35:29.19049Z","iopub.status.idle":"2021-07-31T06:35:29.277541Z","shell.execute_reply.started":"2021-07-31T06:35:29.190425Z","shell.execute_reply":"2021-07-31T06:35:29.276207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#RandomForest\nrf_model = RandomForestRegressor(n_estimators=40, max_samples=.4, max_features=15, max_depth=5, random_state=1234)\nrf_model.fit(train_x, train_y)\nprint(\"Training:\", mean_squared_error(train_y, rf_model.predict(train_x), squared=False))\nprint(\"Validation:\", mean_squared_error(val_y, rf_model.predict(val_x), squared=False))","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:35:36.649936Z","iopub.execute_input":"2021-07-31T06:35:36.650355Z","iopub.status.idle":"2021-07-31T06:35:36.806226Z","shell.execute_reply.started":"2021-07-31T06:35:36.650291Z","shell.execute_reply":"2021-07-31T06:35:36.805258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#XgBoost\nxgb_model = xgboost.XGBRegressor(n_estimators=120, eta=0.05, max_depth=3, subsample=0.3, colsample_bytree=0.3, random_state=1234)\nxgb_model.fit(train_x, train_y)\nprint(\"Training:\", mean_squared_error(train_y, xgb_model.predict(train_x), squared=False))\nprint(\"Validation:\", mean_squared_error(val_y, xgb_model.predict(val_x), squared=False))","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:35:38.49784Z","iopub.execute_input":"2021-07-31T06:35:38.498175Z","iopub.status.idle":"2021-07-31T06:35:38.942052Z","shell.execute_reply.started":"2021-07-31T06:35:38.498136Z","shell.execute_reply":"2021-07-31T06:35:38.940982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SVR MODEL\nsvr_model = SVR()\nsvr_model.fit(train_x, train_y)\nprint(\"Training:\", mean_squared_error(train_y, svr_model.predict(train_x), squared=False))\nprint(\"Validation:\", mean_squared_error(val_y, svr_model.predict(val_x), squared=False))","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:35:40.701916Z","iopub.execute_input":"2021-07-31T06:35:40.702286Z","iopub.status.idle":"2021-07-31T06:35:42.402711Z","shell.execute_reply.started":"2021-07-31T06:35:40.702255Z","shell.execute_reply":"2021-07-31T06:35:42.401691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nTfidfVectorizer = TfidfVectorizer(stop_words='english', max_features=4000)\nTfidfVectorizer.fit(train_sentences)\ntrain_tfidf = TfidfVectorizer.transform(train_sentences)\nval_tfidf = TfidfVectorizer.transform(test_sentences)\n#Ridge\ntfidf_model = Ridge(alpha=3.5, random_state=1234)\ntfidf_model.fit(train_tfidf, train_label)\nprint(\"Training:\", mean_squared_error(train_label, tfidf_model.predict(train_tfidf), squared=False))\nprint(\"Validation:\", mean_squared_error(test_label, tfidf_model.predict(val_tfidf), squared=False))","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:35:43.834266Z","iopub.execute_input":"2021-07-31T06:35:43.834639Z","iopub.status.idle":"2021-07-31T06:35:44.490912Z","shell.execute_reply.started":"2021-07-31T06:35:43.834598Z","shell.execute_reply":"2021-07-31T06:35:44.489853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Stacking**","metadata":{}},{"cell_type":"code","source":"#Model stacking\nridge_model_prediction = ridge_model.predict(val_x)\nrf_model_prediction = rf_model.predict(val_x)\nxgb_model_prediction = xgb_model.predict(val_x)\nsvr_model_prediction = svr_model.predict(val_x)\ntfidf_model_prediction = tfidf_model.predict(TfidfVectorizer.transform(test_sentences))\npredictions = (ridge_model_prediction + rf_model_prediction + xgb_model_prediction + svr_model_prediction + \n               tfidf_model_prediction)/5\nprint(\"Validation:\", mean_squared_error(val_y, predictions, squared=False))","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:35:55.69027Z","iopub.execute_input":"2021-07-31T06:35:55.690801Z","iopub.status.idle":"2021-07-31T06:35:56.071896Z","shell.execute_reply.started":"2021-07-31T06:35:55.690743Z","shell.execute_reply":"2021-07-31T06:35:56.07091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# submission","metadata":{}},{"cell_type":"code","source":"test_data =  pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest_data[\"excerpt\"] = prep_text(test_data[\"excerpt\"])\nids = test_data['id'].values\nval_excerpt = test_data['excerpt'].values\nval_sequences = tokenizer.texts_to_sequences(val_excerpt)\nval_padded = pad_sequences(val_sequences, maxlen=max_len, padding=padding, truncating=truncating)\nval_features = feature_extractor.predict(val_padded)\ndf_val_features = pd.DataFrame(data=val_features)\ntest_x = df_val_features[FEATURE_COLUMNS[0:-1]]\n#Model stacking\nridge_model_prediction = ridge_model.predict(test_x)\nrf_model_prediction = rf_model.predict(test_x)\nxgb_model_prediction = xgb_model.predict(test_x)\nsvr_model_prediction = svr_model.predict(test_x)\ntfidf_model_prediction = tfidf_model.predict(TfidfVectorizer.transform(val_excerpt))\npredictions = (ridge_model_prediction + rf_model_prediction + xgb_model_prediction + svr_model_prediction + \n              tfidf_model_prediction)/5\n#Create DataFrame\nsubmission_df = pd.DataFrame(data=ids, columns=['id'])\nsubmission_df['target'] = predictions\nsubmission_df.to_csv('./submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:35:57.902099Z","iopub.execute_input":"2021-07-31T06:35:57.902517Z","iopub.status.idle":"2021-07-31T06:35:57.9833Z","shell.execute_reply.started":"2021-07-31T06:35:57.902484Z","shell.execute_reply":"2021-07-31T06:35:57.98248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}